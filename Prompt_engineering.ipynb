{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEW/vjelawzv9GmLFEyQW2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SirTee12/LLM-Kaggle-Google-GenAI/blob/main/Prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the SDK"
      ],
      "metadata": {
        "id": "QJ85fhKIppqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e7_t8fZxbZMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9754ec-50af-4c52-ecf6-f3a891cf4bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqy jupyterlab # uninstall jupyterlab in the case it conflict google colab base image\n",
        "!pip install -U -q \"google-genai==1.7.0\" # install google genai library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the SDK and some helpers for rendering the output. The `types` in `import types` may include custom data structures, classes or type hints psecifically to work with google AI. These custom types might represent things like model parameters, input/output formats for AI models or config settings."
      ],
      "metadata": {
        "id": "jkGlMbU9ueF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import HTML, Markdown, display"
      ],
      "metadata": {
        "id": "vn5P5o2Zp4Jd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Call Retry Implementation\n",
        "Set up a retry helper. This allows you to \"Run all\" without worrying about per-minute quota\n",
        "\n",
        "\n",
        "1.  **Imports `retry`:** It imports the `retry` module from `google.api_core`, which provides tools for automatic retries of API calls.\n",
        "\n",
        "2.  **Defines `is_retriable`:**\n",
        "    * It creates a lambda function called `is_retriable`.\n",
        "    * This function checks if an exception (`e`) is an instance of `genai.errors.APIErrpr` and if its error code (`e.code`) is either 429 (Too Many Requests) or 503 (Service Unavailable).\n",
        "    * It returns `True` if both conditions are met (meaning the API call is considered retriable), and `False` otherwise.\n",
        "\n",
        "3.  **Applies Retry Logic:**\n",
        "    * It modifies the `genai.models.Models.generate_content` function by wrapping it with the `retry.retry` function.\n",
        "    * The `retry.retry` function is configured with the `is_retriable` function as the `predicate`. This tells `retry.retry` to only retry the API call if the `is_retriable` function returns `True` for the encountered exception.\n",
        "    * Essentially, this replaces the original `generate_content` function with a new version that automatically retries on 429 and 503 errors, making the code more robust to temporary API issues."
      ],
      "metadata": {
        "id": "JCueWvEs3iyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import retry\n",
        "\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in (429, 503))\n",
        "\n",
        "genai.models.Models.generate_content = retry.Retry(predicate = is_retriable)(genai.models.Models.generate_content)"
      ],
      "metadata": {
        "id": "tyJcQ1EW3tec"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "secret_value_0 = user_secrets.get_secret(\"secret-label-prompt\")"
      ],
      "metadata": {
        "id": "8jzS_Om16DxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the API keys and create a client\n",
        "\n",
        "Retrieves the API key securely and create a client object that will be used to communicate with the generative AI service, using the retrieved API key for authentication."
      ],
      "metadata": {
        "id": "qmMX2ZA28UP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # retrive the APi key\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)   # create a client to interact with the genai application"
      ],
      "metadata": {
        "id": "VpfMD3Jo7_IX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the First Prompt"
      ],
      "metadata": {
        "id": "vaCFpBre_3sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a response\n",
        "response = client.models.generate_content(\n",
        "    model = 'gemini-2.0-flash',\n",
        "    contents = \"Explain AI to me like I'm a kid\"\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "-zXMiooZ_pMB",
        "outputId": "dd28373f-60d7-49b6-e6ea-19df9f36e43b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you have a really smart toy robot! That robot can do things like:\n",
            "\n",
            "*   **Learn from playing:** If you play a game with the robot and show it what's good and bad, it can learn how to play better all by itself, just like you learn new games!\n",
            "*   **Understand what you say:** You can talk to the robot, and it can understand what you mean, even if you don't say it perfectly. It's like having a friend who always knows what you're trying to say!\n",
            "*   **Make guesses about the future:** If you show the robot lots of pictures of cats and dogs, it can learn to tell the difference and guess whether a new picture is a cat or a dog.\n",
            "\n",
            "AI (Artificial Intelligence) is like giving that robot a brain! It's about making computers and robots smart enough to do things that usually only people can do, like learning, understanding, and making decisions.\n",
            "\n",
            "It's not magic, though! People write special instructions (called code) to teach the computer or robot how to do these things. And the more it learns, the smarter it gets!\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Imagine you have a really smart toy robot! That robot can do things like:\n\n*   **Learn from playing:** If you play a game with the robot and show it what's good and bad, it can learn how to play better all by itself, just like you learn new games!\n*   **Understand what you say:** You can talk to the robot, and it can understand what you mean, even if you don't say it perfectly. It's like having a friend who always knows what you're trying to say!\n*   **Make guesses about the future:** If you show the robot lots of pictures of cats and dogs, it can learn to tell the difference and guess whether a new picture is a cat or a dog.\n\nAI (Artificial Intelligence) is like giving that robot a brain! It's about making computers and robots smart enough to do things that usually only people can do, like learning, understanding, and making decisions.\n\nIt's not magic, though! People write special instructions (called code) to teach the computer or robot how to do these things. And the more it learns, the smarter it gets!\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's start a chat"
      ],
      "metadata": {
        "id": "hbQZTsixG3hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model = \"gemini-2.0-flash\", history = [])\n",
        "response = chat.send_message('Hello, my name is Ahmad')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnvlI-MyAZNj",
        "outputId": "72a3a6f9-41d5-4bb8-f2af-d67428b9f451"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Ahmad, it's nice to meet you! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"can you tell me something interesting about dinosaurs\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CZR6L3fHTEP",
        "outputId": "5acfa63a-e44b-4863-88a6-58e3e778aa86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's an interesting fact about dinosaurs that often surprises people:\n",
            "\n",
            "**Some dinosaurs had feathers and might have even been warm-blooded like birds!**\n",
            "\n",
            "For a long time, we thought of dinosaurs as scaly, cold-blooded reptiles. However, discoveries in recent decades, especially in China, have revealed fossil evidence of feathered dinosaurs. These feathers weren't necessarily for flight (although some were), but more likely for insulation, display, or even brooding eggs.\n",
            "\n",
            "Think about that: some of those terrifying predators or giant herbivores might have been fluffy! This discovery has drastically changed our understanding of dinosaur evolution and their connection to modern birds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"do you still remember my name\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS1O0TSqHef2",
        "outputId": "a46614c9-3dfc-4fd3-89ba-dfedb8e961bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, I remember your name is Ahmad. I'm designed to retain information from our conversation to help me better understand and respond to your requests.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chose a model from the Gemini model family\n",
        "\n",
        "Retrieves a list of available AI models, searches for a specific model named \"gemini-2.0-flash,\" and if found, displays its details in a formatted JSON-like structure. The search stops once the target model is located."
      ],
      "metadata": {
        "id": "uUBrfruvh7mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for model in client.models.list():\n",
        "  if model.name == \"models/gemini-2.0-flash\":\n",
        "    pprint(model.to_json_dict())\n",
        "    break"
      ],
      "metadata": {
        "id": "CmeO6A6YIe0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e443edf8-c3f7-45ee-9a00-0a6ff6301a8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': 'Gemini 2.0 Flash',\n",
            " 'display_name': 'Gemini 2.0 Flash',\n",
            " 'input_token_limit': 1048576,\n",
            " 'name': 'models/gemini-2.0-flash',\n",
            " 'output_token_limit': 8192,\n",
            " 'supported_actions': ['generateContent', 'countTokens'],\n",
            " 'tuned_model_info': {},\n",
            " 'version': '2.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters Exploration"
      ],
      "metadata": {
        "id": "Fi_3neIHkzaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Length"
      ],
      "metadata": {
        "id": "MGm-Pg5OmE3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the max number of output token to 200\n",
        "short_config = types.GenerateContentConfig(max_output_tokens = 200)\n",
        "\n",
        "# create a response\n",
        "response_short = client.models.generate_content(\n",
        "    model = 'gemini-2.0-flash',\n",
        "    config = short_config,\n",
        "    contents='write a short essay on the importance of education in modern day society.'\n",
        ")\n",
        "\n",
        "print(response_short.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpL4Sb2oiu7r",
        "outputId": "1495001b-a907-434d-bfe1-596c411bf830"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Cornerstone of Progress: The Indispensable Role of Education in Modern Society\n",
            "\n",
            "In the ever-evolving landscape of the 21st century, education stands as the cornerstone of progress, the bedrock upon which individual fulfillment, societal advancement, and global stability are built. Its importance transcends the mere acquisition of knowledge, encompassing the development of critical thinking, adaptability, and responsible citizenship, all vital components for navigating the complexities of modern life.\n",
            "\n",
            "Firstly, education empowers individuals. It equips them with the skills and knowledge necessary to participate meaningfully in the workforce, fostering economic independence and upward mobility. A well-educated populace is more likely to be innovative, creative, and adaptable to the rapidly changing demands of the job market. Furthermore, education expands horizons, cultivates intellectual curiosity, and promotes personal growth. It allows individuals to understand the world around them, make informed decisions, and contribute to their communities in a meaningful way, ultimately leading to a more fulfilling and engaged life.\n",
            "\n",
            "Beyond individual benefits, education\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature\n",
        "\n",
        "How much randomness is included when selecting the next word (token) in language models depends on the \"temperature\" parameter.  A higher temperature causes the model to take into account a greater number of potential words, producing more inventive and diverse results.  On the other hand, a lower temperature forces the model to adhere to the most likely terms, producing language that is more concentrated and predictable.  The model turns completely deterministic when the temperature is set to 0, always choosing the word that is the most likely.  Temperature does not, however, ensure actual randomness; rather, it is a means of directing the model toward more or less random results."
      ],
      "metadata": {
        "id": "ErIkZR5snjVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a variable to set the temperature\n",
        "high_temp_config = types.GenerateContentConfig(temperature = 2.0)\n",
        "\n",
        "for _ in range(5):\n",
        "  response_temp = client.models.generate_content(\n",
        "      model = 'gemini-2.0-flash',\n",
        "      config = high_temp_config,\n",
        "      contents = 'Pick a random colour... (respond in a single word)'\n",
        "  )\n",
        "\n",
        "  if response_temp.text:\n",
        "    print(response_temp.text, '_' * 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQVK4xyumIuX",
        "outputId": "b2ec1e5d-df52-45d5-e136-b4502a723b4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azure\n",
            " _________________________\n",
            "Orange\n",
            " _________________________\n",
            "Orange\n",
            " _________________________\n",
            "Magenta\n",
            " _________________________\n",
            "Azure\n",
            " _________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9CPCPP9Mox8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}